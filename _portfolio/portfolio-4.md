---
title: "Gaze-based Child Reading Assistant"
summary: "An adaptive AI reading companion using real-time eye-tracking"
tags:
  - Eye-tracking
  - LLM
  - Child-AI
  - Education
hero_image: "/images/childread.png"
excerpt: ""
collection: portfolio
date: 2025-01-15
---

## Overview

This project explores how real-time eye-tracking can be used to adapt AI-generated narrative prompts for children during picture-book reading. The system monitors gaze to detect attention shifts and guides exploration through curiosity-driven storytelling.

## Key Contributions

- Monitors child's gaze to detect engagement and attention shifts in real-time
- Generates child-friendly narrative prompts using large language models
- Guides attention toward unexplored parts of illustrations naturally
- Supports early literacy development through curiosity-driven exploration

## How It Works

<figure>
<img src="/images/childread.png" alt="System overview showing gaze tracking and prompt generation">
<figcaption>The system tracks where the child looks on the page and generates contextual story prompts</figcaption>
</figure>

The system uses a webcam-based eye tracker to monitor where the child is looking on the picture book page. When attention shifts or lingers, the AI generates short, engaging prompts that connect to what the child sees, encouraging them to explore new areas of the illustration.

## My Role & Tech

<div class="two-column">
<div>

### My Role
- Designed the interaction concept and user flow
- Built gaze processing and area-of-interest logic
- Integrated LLM-based prompt generation
- Conducted pilot studies with children

</div>
<div>

### Tech Stack
- **Eye-tracking:** Webcam-based gaze estimation
- **Backend:** Python
- **LLM:** GPT-4 for prompt generation
- **Interface:** Web-based reading interface

</div>
</div>

## Outcome

<span class="status-badge ongoing">Ongoing Project</span>

This is an active research project exploring child-AI interaction in educational contexts.
